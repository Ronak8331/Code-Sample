{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[673   5   5 ... 658  89   5]\n",
      " [  5   5 171 ...  89   5  35]\n",
      " [  5 171 280 ...   5  35 281]\n",
      " ...\n",
      " [ 12  66   4 ...   4 672   8]\n",
      " [ 66   4  92 ... 672   8   6]\n",
      " [  4  92  44 ...   8   6  21]]\n",
      "[ 35 281  28 ...   6  21   9]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 50)            33700     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50, 200)           200800    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 674)               135474    \n",
      "=================================================================\n",
      "Total params: 730,974\n",
      "Trainable params: 730,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 6.3022 - acc: 0.0426\n",
      "Epoch 2/100\n",
      "2558/2558 [==============================] - 29s 11ms/step - loss: 5.8162 - acc: 0.0450\n",
      "Epoch 3/100\n",
      "2558/2558 [==============================] - 31s 12ms/step - loss: 5.6471 - acc: 0.0450\n",
      "Epoch 4/100\n",
      "2558/2558 [==============================] - 32s 13ms/step - loss: 5.5809 - acc: 0.0450\n",
      "Epoch 5/100\n",
      "2558/2558 [==============================] - 31s 12ms/step - loss: 5.5617 - acc: 0.0450\n",
      "Epoch 6/100\n",
      "2558/2558 [==============================] - 71s 28ms/step - loss: 5.5411 - acc: 0.0450\n",
      "Epoch 7/100\n",
      "2558/2558 [==============================] - 94s 37ms/step - loss: 5.5260 - acc: 0.0450\n",
      "Epoch 8/100\n",
      "2558/2558 [==============================] - 77s 30ms/step - loss: 5.5158 - acc: 0.0450\n",
      "Epoch 9/100\n",
      "2558/2558 [==============================] - 71s 28ms/step - loss: 5.5067 - acc: 0.0450\n",
      "Epoch 10/100\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 5.4980 - acc: 0.0450\n",
      "Epoch 11/100\n",
      "2558/2558 [==============================] - 68s 27ms/step - loss: 5.4798 - acc: 0.0450\n",
      "Epoch 12/100\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 5.4373 - acc: 0.0450\n",
      "Epoch 13/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 5.3569 - acc: 0.0450\n",
      "Epoch 14/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 5.2813 - acc: 0.0457\n",
      "Epoch 15/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 5.2166 - acc: 0.0446\n",
      "Epoch 16/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 5.1320 - acc: 0.0446\n",
      "Epoch 17/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 5.0686 - acc: 0.0446\n",
      "Epoch 18/100\n",
      "2558/2558 [==============================] - 68s 27ms/step - loss: 5.0091 - acc: 0.0453\n",
      "Epoch 19/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 4.9324 - acc: 0.0461\n",
      "Epoch 20/100\n",
      "2558/2558 [==============================] - 70s 27ms/step - loss: 4.8692 - acc: 0.0461\n",
      "Epoch 21/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 4.7998 - acc: 0.0457\n",
      "Epoch 22/100\n",
      "2558/2558 [==============================] - 63s 24ms/step - loss: 4.7376 - acc: 0.0461\n",
      "Epoch 23/100\n",
      "2558/2558 [==============================] - 60s 24ms/step - loss: 4.6832 - acc: 0.0489\n",
      "Epoch 24/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 4.6328 - acc: 0.0547\n",
      "Epoch 25/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 4.5831 - acc: 0.0625\n",
      "Epoch 26/100\n",
      "2558/2558 [==============================] - 65s 26ms/step - loss: 4.5539 - acc: 0.0708\n",
      "Epoch 27/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 4.4995 - acc: 0.0711\n",
      "Epoch 28/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 4.4661 - acc: 0.0766\n",
      "Epoch 29/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 4.4387 - acc: 0.0754\n",
      "Epoch 30/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 4.3931 - acc: 0.0782\n",
      "Epoch 31/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 4.3564 - acc: 0.0786\n",
      "Epoch 32/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 4.3282 - acc: 0.0817\n",
      "Epoch 33/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 4.2966 - acc: 0.0880\n",
      "Epoch 34/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 4.2592 - acc: 0.0786\n",
      "Epoch 35/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 4.2262 - acc: 0.0899\n",
      "Epoch 36/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 4.1911 - acc: 0.0868\n",
      "Epoch 37/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 4.1563 - acc: 0.0891\n",
      "Epoch 38/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 4.1370 - acc: 0.0923\n",
      "Epoch 39/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 4.0934 - acc: 0.0973\n",
      "Epoch 40/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 4.0617 - acc: 0.0958\n",
      "Epoch 41/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 4.0367 - acc: 0.0970\n",
      "Epoch 42/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 4.0000 - acc: 0.1067\n",
      "Epoch 43/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.9768 - acc: 0.0989\n",
      "Epoch 44/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.9486 - acc: 0.1005\n",
      "Epoch 45/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.9061 - acc: 0.1048\n",
      "Epoch 46/100\n",
      "2558/2558 [==============================] - 71s 28ms/step - loss: 3.8773 - acc: 0.1091\n",
      "Epoch 47/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.8523 - acc: 0.1071\n",
      "Epoch 48/100\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 3.8274 - acc: 0.1106\n",
      "Epoch 49/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 3.7857 - acc: 0.1106\n",
      "Epoch 50/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.7412 - acc: 0.1200\n",
      "Epoch 51/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.7088 - acc: 0.1196\n",
      "Epoch 52/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.6776 - acc: 0.1196\n",
      "Epoch 53/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 3.6540 - acc: 0.1271\n",
      "Epoch 54/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 3.6306 - acc: 0.1290\n",
      "Epoch 55/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.6027 - acc: 0.1302\n",
      "Epoch 56/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.5688 - acc: 0.1353\n",
      "Epoch 57/100\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 3.5277 - acc: 0.1353\n",
      "Epoch 58/100\n",
      "2558/2558 [==============================] - 65s 26ms/step - loss: 3.5055 - acc: 0.1349\n",
      "Epoch 59/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.4764 - acc: 0.1423\n",
      "Epoch 60/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 3.4397 - acc: 0.1431\n",
      "Epoch 61/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.4154 - acc: 0.1505\n",
      "Epoch 62/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 3.3930 - acc: 0.1525\n",
      "Epoch 63/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.3552 - acc: 0.1501\n",
      "Epoch 64/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.3151 - acc: 0.1611\n",
      "Epoch 65/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.3006 - acc: 0.1626\n",
      "Epoch 66/100\n",
      "2558/2558 [==============================] - 59s 23ms/step - loss: 3.2719 - acc: 0.1697\n",
      "Epoch 67/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.2461 - acc: 0.1673\n",
      "Epoch 68/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.2051 - acc: 0.1810\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.1802 - acc: 0.1814\n",
      "Epoch 70/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 3.1486 - acc: 0.1767\n",
      "Epoch 71/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 3.1113 - acc: 0.1888\n",
      "Epoch 72/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.0930 - acc: 0.2009\n",
      "Epoch 73/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 3.0636 - acc: 0.2005\n",
      "Epoch 74/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 3.0601 - acc: 0.1955\n",
      "Epoch 75/100\n",
      "2558/2558 [==============================] - 63s 24ms/step - loss: 3.0121 - acc: 0.2142\n",
      "Epoch 76/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.9929 - acc: 0.2201\n",
      "Epoch 77/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 2.9601 - acc: 0.2236\n",
      "Epoch 78/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.9330 - acc: 0.2244\n",
      "Epoch 79/100\n",
      "2558/2558 [==============================] - 60s 24ms/step - loss: 2.9134 - acc: 0.2271\n",
      "Epoch 80/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.8648 - acc: 0.2389\n",
      "Epoch 81/100\n",
      "2558/2558 [==============================] - 61s 24ms/step - loss: 2.8428 - acc: 0.2494\n",
      "Epoch 82/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.8331 - acc: 0.2435\n",
      "Epoch 83/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 2.8048 - acc: 0.2565\n",
      "Epoch 84/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.7803 - acc: 0.2506\n",
      "Epoch 85/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.7461 - acc: 0.2576\n",
      "Epoch 86/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.7293 - acc: 0.2561\n",
      "Epoch 87/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.6959 - acc: 0.2733\n",
      "Epoch 88/100\n",
      "2558/2558 [==============================] - 66s 26ms/step - loss: 2.7011 - acc: 0.2725\n",
      "Epoch 89/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.6831 - acc: 0.2740\n",
      "Epoch 90/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.6219 - acc: 0.2948\n",
      "Epoch 91/100\n",
      "2558/2558 [==============================] - 65s 26ms/step - loss: 2.5944 - acc: 0.2998\n",
      "Epoch 92/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.5780 - acc: 0.3010\n",
      "Epoch 93/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 2.5527 - acc: 0.3049\n",
      "Epoch 94/100\n",
      "2558/2558 [==============================] - 62s 24ms/step - loss: 2.5343 - acc: 0.3108\n",
      "Epoch 95/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.6142 - acc: 0.3010\n",
      "Epoch 96/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 2.7950 - acc: 0.2428\n",
      "Epoch 97/100\n",
      "2558/2558 [==============================] - 64s 25ms/step - loss: 2.6065 - acc: 0.2952\n",
      "Epoch 98/100\n",
      "2558/2558 [==============================] - 65s 25ms/step - loss: 2.5599 - acc: 0.3206\n",
      "Epoch 99/100\n",
      "2558/2558 [==============================] - 63s 25ms/step - loss: 2.5012 - acc: 0.3167\n",
      "Epoch 100/100\n",
      "2558/2558 [==============================] - 67s 26ms/step - loss: 2.4707 - acc: 0.3358\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from pickle import dump\n",
    "from keras.utils import to_categorical\n",
    "\t\n",
    "# Read sentences.\n",
    "filename = 'rebuplic_preprocessed.txt'\n",
    "file = open(filename, 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "lines = data.split('\\n')\n",
    "\n",
    "# Convert the words into integers.\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(lines)\n",
    "encoded_lines = t.texts_to_sequences(lines)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# Split the data into X and y\n",
    "encoded_lines = np.array(encoded_lines[:-1]) # Remove last line which is '\\n'\n",
    "X = encoded_lines[:,:-1]\n",
    "y = encoded_lines[:,-1]\n",
    "print (X)\n",
    "print (y)\n",
    "seq_length = len(X[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length = seq_length))\n",
    "model.add(LSTM(200, return_sequences = True))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print (model.summary())\n",
    "\n",
    "y = to_categorical(y, num_classes = vocab_size)\n",
    "model.fit(X,y,batch_size=128, epochs=100)\n",
    "\n",
    "model.save('word_generation_100_epochs.h5')\n",
    "dump(t, open('tokenizer.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
